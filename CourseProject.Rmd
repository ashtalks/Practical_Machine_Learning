---
title: "PracticalMachineLearning"
author: "Anubhav Srivastava"
date: "October 25, 2015"
output: html_document
---
The provided data was analyzed  to determine activity performed by an individual. caret and randomForest were used to generate correct answers for each of the 20 test data cases provided in this assignment.  Seed value was used for consistent results.


```{r}
library(Hmisc)
library(caret)
library(randomForest)
library(foreach)
library(doParallel)
set.seed(2048)
options(warn=-1)
```

First, training and test data provided by COURSERA was loaded and "#DIV/0!" values were replaced with an NA value.

```{r}
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!") )
evaluation_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!") )
```

Columns were casted to be numeric.

```{r}
for(i in c(8:ncol(training_data)-1)) {training_data[,i] = as.numeric(as.character(training_data[,i]))}

for(i in c(8:ncol(evaluation_data)-1)) {evaluation_data[,i] = as.numeric(as.character(evaluation_data[,i]))}
```

Some columns were mostly blank and did not contribute well to the prediction so I only included complete columns, user name, timestamps and windows were removed.  

```{r}
feature_set <- colnames(training_data[colSums(is.na(training_data)) == 0])[-(1:7)]
model_data <- training_data[feature_set]
feature_set
```

The model data was then built from our feature set.

```{r}
idx <- createDataPartition(y=model_data$classe, p=0.75, list=FALSE )
training <- model_data[idx,]
testing <- model_data[-idx,]
```

After this 5 random forests were built with 150 trees each. 
```{r}
registerDoParallel()
x <- training[-ncol(training)]
y <- training$classe

rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree) 
}
```

Error reports for both training and test data are provided.
```{r}
predictions1 <- predict(rf, newdata=training)
confusionMatrix(predictions1,training$classe)


predictions2 <- predict(rf, newdata=testing)
confusionMatrix(predictions2,testing$classe)
```

Conclusions and Test Data Submit
--------------------------------

As can be seen from the confusion matrix this model is very accurate and because the test data was around 99% accurate I expected nearly all of the submitted test cases to be correct.  It turned out they were all correct.

The submission was prepared using COURSERA provided code.

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}


x <- evaluation_data
x <- x[feature_set[feature_set!='classe']]
answers <- predict(rf, newdata=x)

answers

pml_write_files(answers)
```